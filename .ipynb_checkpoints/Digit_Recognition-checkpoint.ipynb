{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from itertools import zip_longest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(data_file, label_file):\n",
    "    # Create dataframe\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    # For each line in the two files\n",
    "    for line_data, line_label in zip_longest(open(data_file), open(label_file)):\n",
    "        # Add data to our array\n",
    "        data.append(list(map(float, line_data.split(','))))\n",
    "        \n",
    "        # Add label to our array\n",
    "        label.append(int(line_label))\n",
    "    \n",
    "    return np.array(data), np.array(label)\n",
    "\n",
    "X, y = extract_data(\"image_0.txt\", \"label.txt\")\n",
    "y[y == 10.] = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Separate data between training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, percentage=0.8):\n",
    "    nb_train_lines = round(500 * percentage)\n",
    "    nb_test_lines = 500 - nb_train_lines\n",
    "    \n",
    "    X_train = np.empty((10 * nb_train_lines, 400))\n",
    "    y_train = np.empty((10 * nb_train_lines))\n",
    "    X_test = np.empty((10 * nb_test_lines, 400))\n",
    "    y_test = np.empty((10 * nb_test_lines))\n",
    "    \n",
    "    for i in range(0, 10):        \n",
    "        X_train[i * nb_train_lines:(i + 1) * nb_train_lines] = X[i * 500:(i * 500) + nb_train_lines]\n",
    "        y_train[i * nb_train_lines:(i + 1) * nb_train_lines] = y[i * 500:(i * 500) + nb_train_lines]\n",
    "        X_test[i * nb_test_lines:(i + 1) * nb_test_lines] = X[(i * 500) + nb_train_lines:(i + 1) * 500]\n",
    "        y_test[i * nb_test_lines:(i + 1) * nb_test_lines] = y[(i * 500) + nb_train_lines:(i + 1) * 500]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Implement the feed-forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34412444, 0.00901156, 0.00579875, ..., 0.43580759, 0.59519184,\n",
       "        0.939997  ],\n",
       "       [0.45455605, 0.02695962, 0.00254916, ..., 0.67302625, 0.65443298,\n",
       "        0.93242882],\n",
       "       [0.64349273, 0.09543054, 0.00463521, ..., 0.91247626, 0.66487608,\n",
       "        0.960016  ],\n",
       "       ...,\n",
       "       [0.70987596, 0.12123413, 0.04247041, ..., 0.8494216 , 0.96073889,\n",
       "        0.93079221],\n",
       "       [0.4761843 , 0.12041015, 0.00767983, ..., 0.68499198, 0.95288608,\n",
       "        0.94294056],\n",
       "       [0.44304614, 0.26165084, 0.00711418, ..., 0.69691512, 0.90733982,\n",
       "        0.80684816]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class FFNN:\n",
    "    \"\"\" Feed-Forward Neural Network with one hidden layer. \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_layer_size):\n",
    "        self.nb_layers = 3\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        # Input with intercept\n",
    "        self.X_intercept = np.empty(0)\n",
    "        \n",
    "        # First level of weights\n",
    "        self.w1 = np.random.randn(input_size + 1, self.hidden_layer_size)\n",
    "        \n",
    "        # First layer output\n",
    "        self.fst_out = np.empty(0)\n",
    "    \n",
    "        # Second level of weights\n",
    "        self.w2 = np.random.randn(self.hidden_layer_size + 1, 10)\n",
    "        \n",
    "        # Second layer output\n",
    "        self.snd_out = np.empty(0)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Add intercept column (column of ones)\n",
    "        self.X_intercept = np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)\n",
    "        \n",
    "        # Multiply by the weights\n",
    "        self.fst_out = np.dot(self.X_intercept, self.w1)\n",
    "        \n",
    "        # Go through the first activation (sigmoid)\n",
    "        self.fst_out = sigmoid(self.fst_out)\n",
    "        \n",
    "        # Add intercept column (column of ones)\n",
    "        self.fst_out = np.concatenate((np.ones((self.fst_out.shape[0], 1)), self.fst_out), axis=1)\n",
    "        \n",
    "        # Multiply by the weights\n",
    "        self.snd_out = np.dot(self.fst_out, self.w2)\n",
    "        \n",
    "        # Go through the second activation (sigmoid)\n",
    "        self.snd_out = sigmoid(self.snd_out)\n",
    "        \n",
    "        return self.snd_out\n",
    "    \n",
    "    def backward(self, Y):\n",
    "        learning_rate = 0.1\n",
    "        \n",
    "        # For all the weights of the first layer\n",
    "        print(self.input_size + 1)\n",
    "        for n in range(self.input_size + 1):\n",
    "            print(n)\n",
    "            for k in range(1, self.hidden_layer_size):\n",
    "                print(k, end=' ')\n",
    "                dgrad_w1 = (self.snd_out - Y) * self.snd_out * (1 - self.snd_out)\n",
    "                \n",
    "                dgrad_w1 *= self.w[k]\n",
    "                \n",
    "                f = np.delete(self.fst_out, 0, axis=1) # we delete the intercept column\n",
    "                print((f[:, k] * (1 - f[:, k]) * self.X_intercept[:, n]).shape)\n",
    "                \n",
    "                # Compute the sum\n",
    "                #for i in range(1, self.X_intercept.shape[0]):\n",
    "                #    for j in range(1, self.snd_out.shape[1]):\n",
    "                #        add = ((self.snd_out[i][j] - Y[i][j]) ** 2)\n",
    "                #        add *= self.snd_out[i][j]\n",
    "                #        add *= self.w2[k][j]\n",
    "                #        add *= np.delete(self.fst_out, 0, axis=1)[i][k] # we delete the intercept column\n",
    "                #        add *= (1 - np.delete(self.fst_out, 0, axis=1)[i][k])\n",
    "                #        add *= self.X_intercept[i][n]\n",
    "                        \n",
    "                #        grad += add\n",
    "                \n",
    "                #self.w1[n][k] -= learning_rate * grad\n",
    "        \n",
    "        \n",
    "\n",
    "ffnn = FFNN(X_train.shape[1], 15)\n",
    "ffnn.forward(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.zeros((len(y_train), 10))\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    Y_train[i][int(y_train[i])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401\n",
      "0\n",
      "1 (4000, 10) (15,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4000,10) (15,) (4000,10) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-2e01d4d33de1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mffnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-43-b8f5226f6aa2>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, Y)\u001b[0m\n\u001b[0;32m     57\u001b[0m                 \u001b[0mdgrad_w1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnd_out\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnd_out\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnd_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdgrad_w1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                 \u001b[0mdgrad_w1\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfst_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# we delete the intercept column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4000,10) (15,) (4000,10) "
     ]
    }
   ],
   "source": [
    "ffnn.backward(Y_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
